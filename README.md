# PEFT
Perform Parameter Efficient Fine-Tuning (PEFT), evaluate the resulting model With ROUGE, and see that the benefits of PEFT outweigh the slightly lower performance metrics

On the Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT  notebook, you will fine-tune a FLAN-T5 model to generate less toxic content with Meta AI's hate speech reward model. The reward model is a binary classifier that predicts either "not hate" or "hate" for the given text. You will use Proximal Policy Optimization (PPO) to fine-tune and reduce the model's toxicity.
